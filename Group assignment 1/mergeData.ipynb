{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open csv\n",
    "for file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     48\u001b[0m     root_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/testSet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 49\u001b[0m     \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mprocess_data\u001b[1;34m(root_folder)\u001b[0m\n\u001b[0;32m      7\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate through all folders in the root folder\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_folder, folder_name)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Check if the folder_path is a directory\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: ''"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to process and combine data\n",
    "def process_data(root_folder):\n",
    "    # Create an empty list to hold the dataframes\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate through all folders in the root folder\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if the folder_path is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Extract person and action from the folder name\n",
    "            parts = folder_name.split(\"-\")\n",
    "            if len(parts) >= 2:\n",
    "                person = parts[0]\n",
    "                action_with_index = parts[1].split(\" \")[0]\n",
    "                action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "                # Iterate through all CSV files in the folder\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.endswith(\".csv\"):\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "\n",
    "                        # Add person and action columns\n",
    "                        data[\"Person\"] = person\n",
    "                        data[\"Action\"] = action\n",
    "\n",
    "                        # Append the dataframe to the list\n",
    "                        all_data.append(data)\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"combined_data.csv\")\n",
    "    combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Combined data saved to {output_path}\")\n",
    "\n",
    "# Main entry point\n",
    "if __name__ == \"__main__\":\n",
    "    root_folder = input(\"datasets/testSet\").strip()\n",
    "    process_data(root_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to datasets/testSet\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].split(\" \")[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    # Read the CSV file\n",
    "                    data = pd.read_csv(file_path)\n",
    "\n",
    "                    # Add person and action columns\n",
    "                    data[\"Person\"] = person\n",
    "                    data[\"Action\"] = action\n",
    "\n",
    "                    # Append the dataframe to the list\n",
    "                    all_data.append(data)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "output_path = os.path.join(root_folder, \"combined_data.csv\")\n",
    "combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Combined data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to datasets/testSet\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    # Read the CSV file\n",
    "                    data = pd.read_csv(file_path)\n",
    "\n",
    "                    # Add person and action columns\n",
    "                    data[\"Person\"] = person\n",
    "                    data[\"Action\"] = action\n",
    "\n",
    "                    # Append the dataframe to the list\n",
    "                    all_data.append(data)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "output_path = os.path.join(root_folder, \"combined_data.csv\")\n",
    "combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Combined data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to datasets/testSet\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "                        \n",
    "                        # Skip empty files\n",
    "                        if data.empty:\n",
    "                            print(f\"Skipping empty file: {file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Add person and action columns\n",
    "                        data[\"Person\"] = person\n",
    "                        data[\"Action\"] = action\n",
    "\n",
    "                        # Append the dataframe to the list\n",
    "                        all_data.append(data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Combine all dataframes into one if any valid data exists\n",
    "if not all_data:\n",
    "    print(\"No valid data found. Combined CSV will not be created.\")\n",
    "else:\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"combined_data.csv\")\n",
    "    combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Combined data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Accelerometer.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Gyroscope.csv does not contain X, Y, Z columns. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Linear Acceleration.csv does not contain X, Y, Z columns. Skipping.\n",
      "No valid data found. Summary CSV will not be created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the summarized data\n",
    "summary_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "\n",
    "                        # Skip empty files\n",
    "                        if data.empty:\n",
    "                            print(f\"Skipping empty file: {file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Calculate statistics for X, Y, Z columns\n",
    "                        if {'X', 'Y', 'Z'}.issubset(data.columns):\n",
    "                            mean_values = data[['X', 'Y', 'Z']].mean()\n",
    "                            std_values = data[['X', 'Y', 'Z']].std()\n",
    "                            min_values = data[['X', 'Y', 'Z']].min()\n",
    "                            max_values = data[['X', 'Y', 'Z']].max()\n",
    "\n",
    "                            # Create a summary row\n",
    "                            summary_row = {\n",
    "                                'Person': person,\n",
    "                                'Action': action,\n",
    "                                'File': file_name,\n",
    "                                'X_mean': mean_values['X'],\n",
    "                                'X_std': std_values['X'],\n",
    "                                'X_min': min_values['X'],\n",
    "                                'X_max': max_values['X'],\n",
    "                                'Y_mean': mean_values['Y'],\n",
    "                                'Y_std': std_values['Y'],\n",
    "                                'Y_min': min_values['Y'],\n",
    "                                'Y_max': max_values['Y'],\n",
    "                                'Z_mean': mean_values['Z'],\n",
    "                                'Z_std': std_values['Z'],\n",
    "                                'Z_min': min_values['Z'],\n",
    "                                'Z_max': max_values['Z']\n",
    "                            }\n",
    "                            summary_data.append(summary_row)\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not contain X, Y, Z columns. Skipping.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Create a dataframe from the summary data\n",
    "if not summary_data:\n",
    "    print(\"No valid data found. Summary CSV will not be created.\")\n",
    "else:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Save the summarized data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"summary_data.csv\")\n",
    "    summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Summary data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "No valid data found. Summary CSV will not be created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the summarized data\n",
    "summary_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "\n",
    "                        # Skip empty files\n",
    "                        if data.empty:\n",
    "                            print(f\"Skipping empty file: {file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Determine which type of data (Accelerometer, Gyroscope, or Linear Acceleration)\n",
    "                        if {'X', 'Y', 'Z'}.issubset(data.columns):\n",
    "                            data_type = \"Accelerometer\"\n",
    "                            columns = ['X', 'Y', 'Z']\n",
    "                        elif {'GyroX', 'GyroY', 'GyroZ'}.issubset(data.columns):\n",
    "                            data_type = \"Gyroscope\"\n",
    "                            columns = ['GyroX', 'GyroY', 'GyroZ']\n",
    "                        elif {'LinAccX', 'LinAccY', 'LinAccZ'}.issubset(data.columns):\n",
    "                            data_type = \"Linear Acceleration\"\n",
    "                            columns = ['LinAccX', 'LinAccY', 'LinAccZ']\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not contain recognized column names. Skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        # Calculate statistics for relevant columns\n",
    "                        mean_values = data[columns].mean()\n",
    "                        std_values = data[columns].std()\n",
    "                        min_values = data[columns].min()\n",
    "                        max_values = data[columns].max()\n",
    "\n",
    "                        # Create a summary row\n",
    "                        summary_row = {\n",
    "                            'Person': person,\n",
    "                            'Action': action,\n",
    "                            'File': file_name,\n",
    "                            'Data_Type': data_type,\n",
    "                            f'{columns[0]}_mean': mean_values[columns[0]],\n",
    "                            f'{columns[0]}_std': std_values[columns[0]],\n",
    "                            f'{columns[0]}_min': min_values[columns[0]],\n",
    "                            f'{columns[0]}_max': max_values[columns[0]],\n",
    "                            f'{columns[1]}_mean': mean_values[columns[1]],\n",
    "                            f'{columns[1]}_std': std_values[columns[1]],\n",
    "                            f'{columns[1]}_min': min_values[columns[1]],\n",
    "                            f'{columns[1]}_max': max_values[columns[1]],\n",
    "                            f'{columns[2]}_mean': mean_values[columns[2]],\n",
    "                            f'{columns[2]}_std': std_values[columns[2]],\n",
    "                            f'{columns[2]}_min': min_values[columns[2]],\n",
    "                            f'{columns[2]}_max': max_values[columns[2]]\n",
    "                        }\n",
    "                        summary_data.append(summary_row)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Create a dataframe from the summary data\n",
    "if not summary_data:\n",
    "    print(\"No valid data found. Summary CSV will not be created.\")\n",
    "else:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Save the summarized data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"summary_data.csv\")\n",
    "    summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Summary data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking1 2024-12-12 14-47-32\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking2 2024-12-12 14-59-19\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-drinking3 2024-12-12 15-13-31\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking1 2024-12-12 15-04-30\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walking2 2024-12-12 15-05-36\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith1 2024-12-12 15-02-42\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\1-walkingwith2 2024-12-12 15-03-33\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking1 2024-12-12 14-50-09\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-drinking2 2024-12-12 15-00-46\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking1 2024-12-12 15-02-53\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking2 2024-12-12 15-03-32\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking3 2024-12-12 15-04-05\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking4 2024-12-12 15-05-25\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walking5 2024-12-12 15-04-41\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith1 2024-12-12 15-06-42\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith2 2024-12-12 15-07-12\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith3 2024-12-12 15-08-16\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith4 2024-12-12 15-07-46\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Accelerometer.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Gyroscope.csv does not contain recognized column names. Skipping.\n",
      "File datasets/testSet\\2-walkingwith5 2024-12-12 15-08-50\\Linear Acceleration.csv does not contain recognized column names. Skipping.\n",
      "No valid data found. Summary CSV will not be created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the summarized data\n",
    "summary_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            summary_row = {\n",
    "                'Person': person,\n",
    "                'Action': action,\n",
    "                \n",
    "            }\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "\n",
    "                        # Skip empty files\n",
    "                        if data.empty:\n",
    "                            print(f\"Skipping empty file: {file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Determine which type of data (Accelerometer, Gyroscope, or Linear Acceleration)\n",
    "                        if {'Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)'}.issubset(data.columns):\n",
    "                            data_type = \"Accelerometer\"\n",
    "                            columns = ['Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)']\n",
    "                        elif {'Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)'}.issubset(data.columns):\n",
    "                            data_type = \"Gyroscope\"\n",
    "                            columns = ['Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)']\n",
    "                        elif {'Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)'}.issubset(data.columns):\n",
    "                            data_type = \"Linear Acceleration\"\n",
    "                            columns = ['Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)']\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not contain recognized column names. Skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        # Calculate statistics for relevant columns\n",
    "                        mean_values = data[columns].mean()\n",
    "                        std_values = data[columns].std()\n",
    "                        min_values = data[columns].min()\n",
    "                        max_values = data[columns].max()\n",
    "\n",
    "                        # Create a summary row\n",
    "                        summary_row = {\n",
    "                            'Person': person,\n",
    "                            'Action': action,\n",
    "                            f'{columns[0]}_mean': mean_values[columns[0]],\n",
    "                            f'{columns[0]}_std': std_values[columns[0]],\n",
    "                            f'{columns[0]}_min': min_values[columns[0]],\n",
    "                            f'{columns[0]}_max': max_values[columns[0]],\n",
    "                            f'{columns[1]}_mean': mean_values[columns[1]],\n",
    "                            f'{columns[1]}_std': std_values[columns[1]],\n",
    "                            f'{columns[1]}_min': min_values[columns[1]],\n",
    "                            f'{columns[1]}_max': max_values[columns[1]],\n",
    "                            f'{columns[2]}_mean': mean_values[columns[2]],\n",
    "                            f'{columns[2]}_std': std_values[columns[2]],\n",
    "                            f'{columns[2]}_min': min_values[columns[2]],\n",
    "                            f'{columns[2]}_max': max_values[columns[2]]\n",
    "                        }\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "            summary_data.append(summary_row)\n",
    "# Create a dataframe from the summary data\n",
    "if not summary_data:\n",
    "    print(\"No valid data found. Summary CSV will not be created.\")\n",
    "else:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Save the summarized data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"summary_data.csv\")\n",
    "    summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Summary data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary data saved to datasets/testSet\\summary_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the summarized data\n",
    "summary_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            summary_row = {\n",
    "                'Person': person,\n",
    "                'Action': action,\n",
    "                \n",
    "            }\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "\n",
    "                        # Skip empty files\n",
    "                        if data.empty:\n",
    "                            print(f\"Skipping empty file: {file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Determine which type of data (Accelerometer, Gyroscope, or Linear Acceleration)\n",
    "                        if {'Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)'}.issubset(data.columns):\n",
    "                            data_type = \"Accelerometer\"\n",
    "                            columns = ['Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)']\n",
    "                        elif {'Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)'}.issubset(data.columns):\n",
    "                            data_type = \"Gyroscope\"\n",
    "                            columns = ['Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)']\n",
    "                        elif {'Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)'}.issubset(data.columns):\n",
    "                            data_type = \"Linear Acceleration\"\n",
    "                            columns = ['Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)']\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not contain recognized column names. Skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        # Calculate statistics for relevant columns\n",
    "                        mean_values = data[columns].mean()\n",
    "                        std_values = data[columns].std()\n",
    "                        min_values = data[columns].min()\n",
    "                        max_values = data[columns].max()\n",
    "\n",
    "                        # Create a summary row\n",
    "                        summary_row = {\n",
    "                            'Person': person,\n",
    "                            'Action': action,\n",
    "                            f'{columns[0]}_mean': mean_values[columns[0]],\n",
    "                            f'{columns[0]}_std': std_values[columns[0]],\n",
    "                            f'{columns[0]}_min': min_values[columns[0]],\n",
    "                            f'{columns[0]}_max': max_values[columns[0]],\n",
    "                            f'{columns[1]}_mean': mean_values[columns[1]],\n",
    "                            f'{columns[1]}_std': std_values[columns[1]],\n",
    "                            f'{columns[1]}_min': min_values[columns[1]],\n",
    "                            f'{columns[1]}_max': max_values[columns[1]],\n",
    "                            f'{columns[2]}_mean': mean_values[columns[2]],\n",
    "                            f'{columns[2]}_std': std_values[columns[2]],\n",
    "                            f'{columns[2]}_min': min_values[columns[2]],\n",
    "                            f'{columns[2]}_max': max_values[columns[2]]\n",
    "                        }\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "            summary_data.append(summary_row)\n",
    "# Create a dataframe from the summary data\n",
    "if not summary_data:\n",
    "    print(\"No valid data found. Summary CSV will not be created.\")\n",
    "else:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Save the summarized data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"summary_data.csv\")\n",
    "    summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Summary data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary data saved to datasets/testSet\\summary_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the root folder containing the action folders\n",
    "root_folder = \"datasets/testSet\"\n",
    "\n",
    "# Create an empty list to hold the summarized data\n",
    "summary_data = []\n",
    "\n",
    "# Iterate through all folders in the root folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "    # Check if the folder_path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract person and action from the folder name\n",
    "        parts = folder_name.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            person = parts[0]\n",
    "            action_with_index = parts[1].rsplit(\" \", 1)[0]\n",
    "            action = ''.join([i for i in action_with_index if not i.isdigit()])\n",
    "\n",
    "            summary_row = {\n",
    "                'Person': person,\n",
    "                'Action': action,\n",
    "                \n",
    "            }\n",
    "\n",
    "            # Iterate through all CSV files in the folder\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Read the CSV file\n",
    "                        data = pd.read_csv(file_path)\n",
    "\n",
    "                        # Skip empty files\n",
    "                        if data.empty:\n",
    "                            print(f\"Skipping empty file: {file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Determine which type of data (Accelerometer, Gyroscope, or Linear Acceleration)\n",
    "                        if {'Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)'}.issubset(data.columns):\n",
    "                            data_type = \"Accelerometer\"\n",
    "                            columns = ['Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)']\n",
    "                        elif {'Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)'}.issubset(data.columns):\n",
    "                            data_type = \"Gyroscope\"\n",
    "                            columns = ['Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)']\n",
    "                        elif {'Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)'}.issubset(data.columns):\n",
    "                            data_type = \"Linear Acceleration\"\n",
    "                            columns = ['Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)']\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not contain recognized column names. Skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        # Calculate statistics for relevant columns\n",
    "                        mean_values = data[columns].mean()\n",
    "                        std_values = data[columns].std()\n",
    "                        min_values = data[columns].min()\n",
    "                        max_values = data[columns].max()\n",
    "\n",
    "                        # add to the summary row\n",
    "                        for col in columns:\n",
    "                            summary_row[f'{col}_mean'] = mean_values[col]\n",
    "                            summary_row[f'{col}_std'] = std_values[col]\n",
    "                            summary_row[f'{col}_min'] = min_values[col]\n",
    "                            summary_row[f'{col}_max'] = max_values[col]\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "            summary_data.append(summary_row)\n",
    "# Create a dataframe from the summary data\n",
    "if not summary_data:\n",
    "    print(\"No valid data found. Summary CSV will not be created.\")\n",
    "else:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Save the summarized data to a single CSV file\n",
    "    output_path = os.path.join(root_folder, \"summary_data.csv\")\n",
    "    summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Summary data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
